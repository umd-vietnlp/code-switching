{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eda8c3fa-d8d5-4888-b30c-7cdbfb1d1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import requests\n",
    "import aiohttp\n",
    "import sseclient\n",
    "import time\n",
    "\n",
    "\n",
    "FIREWORKS_API_ENDPOINT = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
    "TOGETHER_API_ENDPOINT = \"https://api.together.xyz/v1/chat/completions\"\n",
    "OPENAI_API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
    "CLAUDE_API_ENDPOINT = \"https://api.anthropic.com/v1/messages\"\n",
    "# HEADERS = {\n",
    "#   \"accept\": \"application/json\",\n",
    "#   \"content-type\": \"application/json\",\n",
    "# }\n",
    "HEADERS = {\n",
    "  \"accept\": \"application/json\",\n",
    "  \"content-type\": \"application/json\",\n",
    "  \"anthropic-version\": \"2023-06-01\",\n",
    "}\n",
    "\n",
    "\n",
    "class LLMEngine:\n",
    "  def __init__(self, api_endpoint: str, api_key: str):\n",
    "    self.api_endpoint = api_endpoint\n",
    "    self.headers = HEADERS.copy()\n",
    "    if self.api_endpoint == CLAUDE_API_ENDPOINT:\n",
    "        self.headers.update({\"x-api-key\": api_key})\n",
    "    else:\n",
    "        self.headers.update({\"Authorization\": f\"Bearer {api_key}\"})\n",
    "\n",
    "  def generate(\n",
    "      self,\n",
    "      messages: List[Dict[str, str]],\n",
    "      model: str,\n",
    "      temperature: float = 0.0,\n",
    "      top_p: float = 1.0,\n",
    "      max_new_tokens: int = 2048,\n",
    "      stop_sequences: List[str] = None,\n",
    "      **kwargs\n",
    "  ):\n",
    "    if self.api_endpoint == CLAUDE_API_ENDPOINT:\n",
    "        payload = {\n",
    "          \"model\": model,\n",
    "          \"messages\": messages,\n",
    "          \"max_tokens\": max_new_tokens,\n",
    "          \"temperature\": temperature,\n",
    "          \"top_p\": top_p,\n",
    "          \"top_k\": 1,\n",
    "          \"stream\": False,\n",
    "        }\n",
    "        response = requests.post(self.api_endpoint, json=payload, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['content'][0]['text']\n",
    "    else:\n",
    "        payload = {\n",
    "          \"model\": model,\n",
    "          \"messages\": messages,\n",
    "          \"max_tokens\": max_new_tokens,\n",
    "          \"temperature\": temperature,\n",
    "          \"top_p\": top_p,\n",
    "          \"stream\": False,\n",
    "          \"stop\": stop_sequences,\n",
    "        }\n",
    "        response = requests.post(self.api_endpoint, json=payload, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "  async def agenerate(\n",
    "    self,\n",
    "    messages: List[Dict[str, str]],\n",
    "    model: str,\n",
    "    temperature: float = 0.0,\n",
    "    top_p: float = 1.0,\n",
    "    max_new_tokens: int = 2048,\n",
    "    stop_sequences: List[str] = None,\n",
    "    **kwargs\n",
    "  ):\n",
    "    if self.api_endpoint == CLAUDE_API_ENDPOINT:\n",
    "        payload = {\n",
    "          \"model\": model,\n",
    "          \"messages\": messages,\n",
    "          \"max_tokens\": max_new_tokens,\n",
    "          \"temperature\": temperature,\n",
    "          \"top_p\": top_p,\n",
    "          \"top_k\": 1,\n",
    "          \"stream\": False,\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "          async with session.post(self.api_endpoint, json=payload, headers=self.headers) as response:\n",
    "            response.raise_for_status()\n",
    "            response_json = await response.json()\n",
    "            return response_json['content'][0]['text']\n",
    "    else:\n",
    "        payload = {\n",
    "          \"model\": model,\n",
    "          \"messages\": messages,\n",
    "          \"max_tokens\": max_new_tokens,\n",
    "          \"temperature\": temperature,\n",
    "          \"top_p\": top_p,\n",
    "          \"stream\": False,\n",
    "          \"stop\": stop_sequences,\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "          async with session.post(self.api_endpoint, json=payload, headers=self.headers) as response:\n",
    "            response.raise_for_status()\n",
    "            response_json = await response.json()\n",
    "            return response_json['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13eff0b8-070e-4d39-9743-80ba85f2716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"<insert api key>\"\n",
    "engine = LLMEngine(OPENAI_API_ENDPOINT, api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "790f429a-eb8f-440e-89fc-9e93360f0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_PROMPT = \"\"\"\n",
    "Detect if the given Vietnamese text contains any English words. If English words are present, classify each as either a loanword, code-mixed indexicality, or code-switching, then translate the entire text into English.\n",
    "\n",
    "# Steps\n",
    "1. *Detection*: Detect whether the given text contains English words.\n",
    "2. *Classification*: If English words are detected, classify each word as either a \"loanword\" (a word borrowed from English, adapted into Vietnamese); \"code-mixed-indexicality\" (word- or phrase-level stylistic language choice that signal belongingness to a social subgroup e.g. Gen Z, academics, businessperson, etc); or \"code-switching\" (word or phrase where Vietnamese-English language switch are seamless and does not represent personal/speaker linguistic style).  \n",
    "3. *Translation*: Translate the entire text into English accurately.\n",
    "\n",
    "# Output Format\n",
    "- *Detection Result*: Output \"True\" if English words are present, \"0\" otherwise.\n",
    "- *Classification*: If applicable, provide a list of English words with their classification as either \"loanword\" or \"code-mixed-indexicality\" or \"code-switching\".\n",
    "- *Translation*: If applicable, provide the English translation.\n",
    "\n",
    "# Examples\n",
    "*Example 1:*\n",
    "\n",
    "Input: \"T√¥i th√≠ch ƒëi shopping v√†o cu·ªëi tu·∫ßn.\"\n",
    "- Detection Result: True\n",
    "- Classification:\n",
    "- \"shopping\": loanword\n",
    "- Translation: \"I like to go shopping on weekends.\"\n",
    "\n",
    "*Example 2:*\n",
    "\n",
    "Input: \"T√¥i th√≠ch ƒëi mua s·∫Øm v√†o cu·ªëi tu·∫ßn.\"\n",
    "- Detection Result: False\n",
    "\n",
    "# Notes\n",
    "\n",
    "- Only proceed to classification and translation if English words are detected.\n",
    "- Ensure accurate classification of English words to distinguish between loanwords and code-mixed-indexicality and code-switching.\n",
    "\n",
    "---\n",
    "\n",
    "Input: {input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d07d0f-39ad-4ba2-81a7-f4a499f34546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"1000 followers Moon s·∫Ω m·ªü giveaway b·ªô 3000 t·ª´ v·ª±ng ti·∫øng Anh th√¥ng d·ª•ng nh·∫•t cho c·∫£ nh√† nha ü§©\",\n",
    "    \"M√åNH C√ì TH·∫ÆC M·∫ÆC ? L∆Ø∆†NG TR·ª¢ L√ù M·ªçi ng∆∞·ªùi s·∫Ω thu√™ tr·ª£ l√Ω part time v√† full time. L∆∞∆°ng mn tr·∫£ cho tr·ª£ l√Ω l√† bao nhi√™u? N·∫øu c√¥ng vi·ªác l√†: - Ch·ª•p ·∫£nh, qu·∫£n l√Ω time nh·∫Øc h·∫°n job - Ph·ª• tr√°ch up b√†i, qu·∫£n l√Ω l·ªãch job - Edit n·∫øu c·∫ßn (ko q√° c·∫ßn thi·∫øt c√°i n√†y) - ƒêi theo event n·∫øu c·∫ßn thi·∫øt M·ªçi ng∆∞·ªùi share √≠t salary mn tr·∫£ cho tr·ª£ l√Ω vs ƒëc khum. M√¨nh tham kh·∫£o c√°i. M√¨nh tr·∫£ 150k/h v·ªõi part time l√† cao hay th·∫•p v mn ?\",\n",
    "    \"First thread c·ªßa em l√† l·ªùi k√™u c·ª©u nh·ªù gi·∫£ng b√†i üò≠ Em h·ªçc accounting and finance nƒÉm nh·∫•t ·∫•y ·∫°, m√† ch∆∞a g√¨ em ƒë√£ kh√¥ng hi·ªÉu debit and credit r·ªìi ;-; ki·ªÉu em kh√¥ng hi·ªÉu c√°i b·∫£n ch·∫•t c·ªßa n√≥ √Ω (t·∫°i sao revenue l·∫°i l√† credit v·∫≠y) m·ªçi ng∆∞·ªùi ·∫° ai ƒë·∫•y gi√∫p em v·ªõi huhu c√¥ng ƒë·ª©c v√¥ l∆∞·ª£ng üò≠üôèüèª\",\n",
    "    \"T·∫°i case c·ªßa anh c≈©ng h∆°i kh√°c do anh m·∫•t th·ªùi gian kh√° d√†i nh∆∞ng anh nghƒ© l√† xin intern r·ªìi ch·ªù c∆° h·ªôi. V·ªõi l·∫°i n√†y kh√¥ng ph·∫£i l√† th√†nh t·ª±u em ∆°i v√¨ c√°i n√†y l√† ki·ªÉu partnership c·ªßa b√™n c√¥ng ty v·ªõi ƒë·ªëi t√°c ƒë·ªÉ hi·ªÉu th√™m v·ªÅ c√°ch v·∫≠n h√†nh c·ªßa TV b√™n Channel 7 th√¥i. M·∫•y c√°i n√†y th√¨ ai trong c√¥ng ty l√†m m·∫£ng media c≈©ng s·∫Ω t·ªï ch·ª©c thui √°.\",\n",
    "    \"ohh z ch√∫c b√† may m·∫Øn nhenn. V·ªõi l·∫°i tui hay x√†i m·∫•y c√°i generic ki·ªÉu ‚Äúi know your company stands for DEI and it deeply resonates w me ki·ªÉu z :))) nghe generic nhma tui n√≥i z v·∫´n dc move forward v√≤ng ti·∫øp theo lun √°\",\n",
    "    \"C√≥ ai c·∫£m th·∫•y ƒëi h·ªçc, h·ªçc bao nhi√™u c√°i framework ƒë·∫øn l√∫c ƒëi l√†m v·ªõ ph·∫£i start up n√≥ l·ªôn t√πng ph√®o kh√¥ng? ƒê·∫øn l√∫c mu·ªën purpose framework c≈©ng kh√≥ n·ªØa ch∆∞a k·ªÉ l√† trong m√¥i tr∆∞·ªùng ƒë√≥ m√¨nh c≈©ng d·ªÖ b·ªã fomo n√≥i l√† h·ªçc nhanh nh∆∞ng m√† ch∆∞a ch·∫Øc ƒë√£ s√¢u.\",\n",
    "    \"·ªû b√†i s·ª≠a n√†y th√¨ t√¥i ƒë√£ th√™m v√†o m·ªôt s·ªë ph∆∞∆°ng √°n thay th·∫ø cho vi·ªác \\\"strict punishments\\\" effective h∆°n v√† t·ª´ ƒë√≥ suy ra l√† t√¥i disagree v·ªõi vi·ªác \\\"strict punishments\\\" l√† the only way.\",\n",
    "    \"Stb s·ªë 1, bread factory l√† h√†ng b√°nh nh∆∞ng n∆∞·ªõc c≈©ng ngon top 2\",\n",
    "    \"Anh nh·∫≠n ƒë·ªãnh r·∫±ng c√≥ th·ªÉ Examiner ƒë√£ ƒë√°nh gi√° cao m√¨nh ·ªü 2 ti√™u ch√≠ Lexical Resource v√† GR &Accuracy. C·ª• th·ªÉ khi ƒë∆∞·ª£c h·ªèi l√† Ch√≠nh ph·ªß n√™n tr·ª´ng ph·∫°t nh·ªØng DN g√¢y √¥ nhi·ªÖm hay khuy·∫øn kh√≠ch khen th∆∞·ªüng h·ªç nh√¨u h∆°n cho nh·ªØng h√†nh ƒë·ªông v√¨ m√¥i tr∆∞·ªùng th√¨ m√¨nh c√≥ tr·∫£ l·ªùi ‚ÄúPunitive measures just act as a deterrent in the short term, not a feasible solution in the long run‚Äù.\",\n",
    "    \"Book l·ªãch 3 th√°ng, t·ªõi ng√†y h·∫πn b√°c sƒ© g·ªçi tr∆∞·ªõc n·ª≠a ti·∫øng cancel h·∫πn . Nge xong h·∫øt b·ªánh ü§£\",\n",
    "    \"Congrats. Btw t·ªõ c√≥ th·ªÉ connect ƒë·ªÉ c√≥ th·ªÉ t√¨m job IT remote d·ªÖ h∆°n ƒë∆∞·ª£c kh√¥ng?\",\n",
    "    \"kh√¥ng bi·∫øt Vi·ªát Nam c√≥ cty n√†o in ship n·ªôi ƒë·ªãa kh√¥ng ch·ª© c√°i c·ªù ƒëeo c·ªï h√¥m nay l√† m√£ customized graduation stole m·∫•y c√¥ng ty POD Vi·ªát Nam ch·∫°y m√£ cho n∆∞·ªõc ngo√†i nhi·ªÅu l·∫Øm, m√†u v·∫£i n√†y x∆∞·ªüng TQ c√≥ s·∫µn c·∫£.\",\n",
    "    \"Tham gia nh√≥m h√≥ng hint free, t√†i li·ªáu free v√† c√°c g√≥i √¥n t·ªß c√°c th√°ng 10-11-12 t·∫°i ƒë√¢y nh√©\",\n",
    "    \"Tr·ªùi ∆°i d·∫ßn d·∫ßn Quang H√πng chi·∫øm lu√¥n c√°i tik tok c·ªßa t lu√¥n √°. Xong c≈©ng v√¨ th·∫ø m√† t bi·∫øt nhi·ªÅu c√°i h∆°n v·ªÅ H√πng. C√≥ nhi·ªÅu c√°i t th∆∞∆°ng d·ªØ l·∫Øm. R·ªìi c·∫£ ƒë·∫øn l√∫c ƒë∆∞·ª£c debut trong Best Five c·ªßa ATSH n·ªØa l√† t kh√≥c lu√¥n √°aaaaüò≠üò≠. L·∫ßn ƒë·∫ßu ti√™n stan idol m√† c≈©ng l√† idol Vi·ªát Nam n·ªØa n√™n t c·∫£m th·∫•y tuy·ªát v·ªùi l·∫Øm\",\n",
    "    \"Chatgpt should be your best friend. X∆∞a m√¨nh t·ª± h·ªçc code R v·ªõi chatgpt ƒë·ªÉ cook project trong 1 tu·∫ßn.\",\n",
    "]\n",
    "\n",
    "model_name = 'gpt-3.5-turbo'\n",
    "model_name = 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'\n",
    "model_name = 'claude-3-5-sonnet-20240620'\n",
    "\n",
    "\n",
    "\n",
    "with open('gpt4o-300.jsonl', 'w') as out_f:\n",
    "    for example in examples:\n",
    "        prompt = DETECTION_PROMPT.format(input=example)\n",
    "        output = engine.generate([{\n",
    "            'role': 'user', 'content': prompt\n",
    "        }], model=model_name)\n",
    "        json.dump({'output': output, 'input': example, 'model': model_name}, out_f, ensure_ascii=False)\n",
    "        out_f.write('\\n')\n",
    "        print('======================')\n",
    "        print('Input:', example)\n",
    "        print('Output:', output)\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2d627-6a9b-48a2-8bcb-1ab35d99f2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
